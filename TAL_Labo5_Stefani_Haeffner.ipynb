{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 5 : Vector Embedding\n",
    "\n",
    "> Authors : Stefani Massimo, Häffner Edwin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de gensim et scipy en dernière version\n",
    "#!pip install gensim scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installation du modèle entraîné sur Google News \n",
    "from gensim import downloader as api\n",
    "w2v_vectors = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du modèle\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"~/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\", binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse aux questions \n",
    "\n",
    ">a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?\n",
    "\n",
    "Sur mon OS Linux, je vois que le notebook prends 4.57 GiB en mémoire. Visual studio code en prends 8.52 GiB mais je ne pense pas que c'est lié ! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La dimension de l'espace vectoriel est de 300 dimensions\n"
     ]
    }
   ],
   "source": [
    "print(f\"La dimension de l'espace vectoriel est de {w2v_vectors.vector_size} dimensions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c. Quelle est la taille du vocabulaire connu du modèle ? Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du vocabulaire est de 3000000 mots et voici des mots qui sont dans le vocabulaire (ou pas): \n",
      "Connu : natural\n",
      "Connu : language\n",
      "Connu : processing\n",
      "Connu : Yverdon\n",
      "Connu : school\n",
      "Inconnu : bumfuzzle\n",
      "Inconnu : taradiddle\n",
      "Connu : collywobbles\n",
      "Inconnu : Yverdon-Les-Bains\n",
      "Inconnu : Puidoux\n"
     ]
    }
   ],
   "source": [
    "print(f\"La taille du vocabulaire est de {len(w2v_vectors)} mots et voici des mots qui sont dans le vocabulaire (ou pas): \")\n",
    "\n",
    "for word in [\"natural\", \"language\", \"processing\", \"Yverdon\", \"school\", \"bumfuzzle\", \"taradiddle\", \"collywobbles\", \"Yverdon-Les-Bains\", \"Puidoux\"]:\n",
    "    if word in w2v_vectors :\n",
    "        print(f\"Connu : {word}\")\n",
    "    else :\n",
    "        print(f\"Inconnu : {word}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d. Quelle est la similarité entre les mots rabbit et carrot ? Veuillez rappeler comment on mesure les similarités entre deux mots grâce à leurs vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similarité entre \"rabbit\" et \"carrot\" est de : 0.3631\n"
     ]
    }
   ],
   "source": [
    "print('La similarité entre \\\"rabbit\\\" et \\\"carrot\\\" est de : %.4f' % (w2v_vectors.similarity(\"rabbit\", \"carrot\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e. onsidérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la similarité entre les deux mots. Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rabbit'\t'animal'\t0.53\n",
      "'rabbit'\t'hare'\t0.61\n",
      "'rabbit'\t'bunny'\t0.64\n",
      "'rabbit'\t'easter'\t0.19\n",
      "'rabbit'\t'vertex'\t0.07\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('rabbit', 'animal'), # Un lapin EST un animal\n",
    "    ('rabbit', 'hare'), # Le lièvre est un genre de lapin \"sauvage\"\n",
    "    ('rabbit', 'bunny'),  # Version cute de lapin\n",
    "    ('rabbit', 'easter'),    # lapin de Pâques\n",
    "    ('rabbit', 'vertex'), #Rien à voir\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, w2v_vectors.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question e : Discussion\n",
    "\n",
    "- On voit que lapin et animal est assez similaire ce qui fais sens\n",
    "- Lapin et lièvre sont encore plus similaire ce qui fais aussi sens\n",
    "- Un peu bizarre que rabbit et bunny ne soient pas plus similaire que ça vu que c'est littéralement le même animal, juste que bunny est la forme plus colloquial. \n",
    "- Rabbit et easter ne sont pas similaire ce qui fait sens, mais il y a quand même un lien (lapin de Pâques donc la similitude n'est pas si basse)\n",
    "- Enfin rabbit et vertex (sommet) n'ont vraiment rien à voir donc 0.07 n'est pas surprenant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre awful et good 0.4928\n"
     ]
    }
   ],
   "source": [
    "w1 = \"awful\"\n",
    "w2 = \"good\"\n",
    "print(f'Similarité entre {w1} et {w2} %.4f' % (w2v_vectors.similarity(w1, w2)))\n",
    "\n",
    "\n",
    "# Comment expliquez-vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?\n",
    "# Je pense que awful et good peuvent être utilisé dans des même contexte, comme lorsqu'on a un article qui évalue des choses, on peut à la fois considérer quelque chose de bon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g. En vous aidant de la documentation de Gensim sur KeyedVectors, obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353. Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'Patrick_Nyarko' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtest\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datapath\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m pearson_result, significance_result, _ = \u001b[43mw2v_vectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_word_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatapath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwordsim353.tsv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRésultat de Pearson :\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Statistique : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpearson_result.statistic\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages/gensim/models/keyedvectors.py:1466\u001b[39m, in \u001b[36mKeyedVectors.evaluate_word_pairs\u001b[39m\u001b[34m(self, pairs, delimiter, encoding, restrict_vocab, case_insensitive, dummy4unknown)\u001b[39m\n\u001b[32m   1464\u001b[39m ok_keys = \u001b[38;5;28mself\u001b[39m.index_to_key[:restrict_vocab]\n\u001b[32m   1465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m case_insensitive:\n\u001b[32m-> \u001b[39m\u001b[32m1466\u001b[39m     ok_vocab = \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mok_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1468\u001b[39m     ok_vocab = {k: \u001b[38;5;28mself\u001b[39m.get_index(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(ok_keys)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages/gensim/models/keyedvectors.py:1466\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1464\u001b[39m ok_keys = \u001b[38;5;28mself\u001b[39m.index_to_key[:restrict_vocab]\n\u001b[32m   1465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m case_insensitive:\n\u001b[32m-> \u001b[39m\u001b[32m1466\u001b[39m     ok_vocab = {k.upper(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(ok_keys)}\n\u001b[32m   1467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1468\u001b[39m     ok_vocab = {k: \u001b[38;5;28mself\u001b[39m.get_index(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(ok_keys)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages/gensim/models/keyedvectors.py:420\u001b[39m, in \u001b[36mKeyedVectors.get_index\u001b[39m\u001b[34m(self, key, default)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not present\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"Key 'Patrick_Nyarko' not present\""
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "pearson_result, significance_result, _ = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "print(\"Résultat de Pearson :\")\n",
    "print(f\"  Statistique : {pearson_result.statistic}\")\n",
    "print(f\"  Valeur P : {pearson_result.pvalue}\")\n",
    "\n",
    "print(\"\\nRésultat de Significativité (Spearman) :\")\n",
    "print(f\"  Statistique : {significance_result.statistic}\")\n",
    "print(f\"  Valeur P : {significance_result.pvalue}\")\n",
    "\n",
    "print(\"Le resultat est TODO trop la flemme là\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">h. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données\n",
    "questions-words.txt. Attention, cette évaluation prend une dizaine de minutes, donc il vaut\n",
    "mieux commencer par tester avec un fragment de ce fichier (copier/coller les 100 premières\n",
    "analogies). Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'Patrick_Nyarko' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m word_analogies = \u001b[43mw2v_vectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_word_analogies\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./question-words-small.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(word_analogies)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages/gensim/models/keyedvectors.py:1328\u001b[39m, in \u001b[36mKeyedVectors.evaluate_word_analogies\u001b[39m\u001b[34m(self, analogies, restrict_vocab, case_insensitive, dummy4unknown, similarity_function)\u001b[39m\n\u001b[32m   1326\u001b[39m ok_keys = \u001b[38;5;28mself\u001b[39m.index_to_key[:restrict_vocab]\n\u001b[32m   1327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m case_insensitive:\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m     ok_vocab = \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mok_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1330\u001b[39m     ok_vocab = {k: \u001b[38;5;28mself\u001b[39m.get_index(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(ok_keys)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages/gensim/models/keyedvectors.py:1328\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1326\u001b[39m ok_keys = \u001b[38;5;28mself\u001b[39m.index_to_key[:restrict_vocab]\n\u001b[32m   1327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m case_insensitive:\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m     ok_vocab = {k.upper(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(ok_keys)}\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1330\u001b[39m     ok_vocab = {k: \u001b[38;5;28mself\u001b[39m.get_index(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(ok_keys)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages/gensim/models/keyedvectors.py:420\u001b[39m, in \u001b[36mKeyedVectors.get_index\u001b[39m\u001b[34m(self, key, default)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not present\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"Key 'Patrick_Nyarko' not present\""
     ]
    }
   ],
   "source": [
    "word_analogies = w2v_vectors.evaluate_word_analogies(\"./question-words-small.txt\") \n",
    "\n",
    "print(word_analogies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. En utilisant gensim.downloader (voir question 1) récupérez le corpus qui contient les 108 pre-\n",
    "miers caractères de Wikipédia (en anglais) avec la commande : corpus = api.load('text8').\n",
    "Combien de phrases et de mots (tokens) possède ce corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = api.load('text8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le corpus contient 1701 phrases et 17005207 mots (tokens).\n"
     ]
    }
   ],
   "source": [
    "# Calcul du nombre de phrases et de mots (tokens) dans le corpus\n",
    "num_sentences = sum(1 for _ in corpus)\n",
    "num_tokens = sum(len(sentence) for sentence in corpus)\n",
    "\n",
    "print(f\"Le corpus contient {num_sentences} phrases et {num_tokens} mots (tokens).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus (voir la documentation de\n",
    "Word2vec). Si nécessaire, procédez progressivement, en commençant par utiliser 1% du corpus,\n",
    "puis 10%, etc., pour contrôler le temps nécessaire.\n",
    "\n",
    "> • Veuillez indiquer la dimension choisie pour le embedding de ce nouveau modèle.\n",
    "> • Combien de temps prend l’entraînement sur le corpus total ?\n",
    "> • Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "def train_word2vec_model(corpus, num_sentences, vector_size=100, window=5, min_count=5, workers=4, percent=1):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle Word2Vec sur le corpus donné.\n",
    "    \n",
    "    :param corpus: Corpus d'entraînement\n",
    "    :param num_sentences: Nombre total de phrases dans le corpus\n",
    "    :param vector_size: Dimension des vecteurs de mots\n",
    "    :param window: Taille de la fenêtre contextuelle\n",
    "    :param min_count: Fréquence minimale des mots pour être inclus dans le vocabulaire\n",
    "    :param workers: Nombre de threads à utiliser pour l'entraînement\n",
    "    :param percent: Pourcentage de phrases à utiliser pour l'entraînement. Default = 1 (100%)\n",
    "    :return: Modèle Word2Vec entraîné\n",
    "    \"\"\"\n",
    "    # Limiter le corpus à un certain pourcentage\n",
    "    num_sentences_limited = int(num_sentences * percent)\n",
    "    limited_corpus = [sentence for i, sentence in enumerate(corpus) if i < num_sentences_limited]    \n",
    "    # Entraîner le modèle Word2Vec\n",
    "    model = Word2Vec(sentences=limited_corpus, vector_size=vector_size, window=window, min_count=min_count, workers=workers)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle entraîné sur 1% du corpus.\n"
     ]
    }
   ],
   "source": [
    "model_1_percent = train_word2vec_model(corpus, num_sentences, percent=0.01)\n",
    "print(\"Modèle entraîné sur 1% du corpus.\")\n",
    "## Pour 1% il a mis 5 secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_percent.save(\"word2vec_model_1_percent.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle entraîné sur 10% du corpus.\n"
     ]
    }
   ],
   "source": [
    "model_10_percent = train_word2vec_model(corpus, num_sentences, percent=0.1)\n",
    "print(\"Modèle entraîné sur 10% du corpus.\")\n",
    "# Pour 10% il a mis 14.2 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10_percent.save(\"word2vec_model_10_percent.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle entraîné sur 50% du corpus.\n"
     ]
    }
   ],
   "source": [
    "model_50_percent = train_word2vec_model(corpus, num_sentences, percent=0.5)\n",
    "print(\"Modèle entraîné sur 50% du corpus.\")\n",
    "# Pour 50% il a mis 1 minute et 8.6 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50_percent.save(\"word2vec_model_50_percent.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle entraîné sur 100% du corpus.\n"
     ]
    }
   ],
   "source": [
    "model_100_percent = train_word2vec_model(corpus, num_sentences)\n",
    "print(\"Modèle entraîné sur 100% du corpus.\")\n",
    "# Pour 100% il a mis 2 minutes et 19.3 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_100_percent.save(\"word2vec_model_100_percent.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du modèle 1% : 3.18 Mo\n",
      "Taille du modèle 10% : 15.41 Mo\n",
      "Taille du modèle 50% : 38.64 Mo\n",
      "Taille du modèle 100% : 56.47 Mo\n"
     ]
    }
   ],
   "source": [
    "## Taille du modèle\n",
    "import os\n",
    "model_1_percent_size = os.path.getsize(\"word2vec_model_1_percent.model\")\n",
    "model_10_percent_size = os.path.getsize(\"word2vec_model_10_percent.model\")\n",
    "model_50_percent_size = os.path.getsize(\"word2vec_model_50_percent.model\")\n",
    "model_100_percent_size = os.path.getsize(\"word2vec_model_100_percent.model\")\n",
    "print(f\"Taille du modèle 1% : {model_1_percent_size / (1024 * 1024):.2f} Mo\")\n",
    "print(f\"Taille du modèle 10% : {model_10_percent_size / (1024 * 1024):.2f} Mo\")\n",
    "print(f\"Taille du modèle 50% : {model_50_percent_size / (1024 * 1024):.2f} Mo\")\n",
    "print(f\"Taille du modèle 100% : {model_100_percent_size / (1024 * 1024):.2f} Mo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c. Mesurez la qualité de ce modèle comme en (1g) et (1h). Ce modèle est-il meilleur que celui\n",
    "entraîné sur Google News ? Quelle est selon vous la raison de la différence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de Pearson :\n",
      "  Statistique : 0.61279167504479\n",
      "  Valeur P : 1.4441947122085646e-37\n",
      "\n",
      "Résultat de Significativité (Spearman) :\n",
      "  Statistique : 0.6297061028934455\n",
      "  Valeur P : 3.5781649100668985e-40\n",
      "Précision des analogies : 0.36\n"
     ]
    }
   ],
   "source": [
    "pearson_result_small, significance_result_small, _ = model_100_percent.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "print(\"Résultat de Pearson :\")\n",
    "print(f\"  Statistique : {pearson_result_small.statistic}\")\n",
    "print(f\"  Valeur P : {pearson_result_small.pvalue}\")\n",
    "\n",
    "print(\"\\nRésultat de Significativité (Spearman) :\")\n",
    "print(f\"  Statistique : {significance_result_small.statistic}\")\n",
    "print(f\"  Valeur P : {significance_result_small.pvalue}\")\n",
    "\n",
    "# Evaluate word analogies\n",
    "word_analogies_small = model_100_percent.wv.evaluate_word_analogies(\"./question-words-small.txt\")[0]\n",
    "print(f\"Précision des analogies : {word_analogies_small}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d. Téléchargez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus\n",
    "text8 et des dépêches économiques de Reuters fourni par l’enseignant et appelé\n",
    "wikipedia_augmented.zip (à décompresser en un fichier ‘.dat’ de 413 Mo). Entraînez un\n",
    "nouveau modèle word2vec sur ce corpus, en précisant la dimension choisie pour les embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus_path = \"wikipedia_augmented.dat\"\n",
    "new_corpus = api.load(new_corpus_path)\n",
    "\n",
    "num_sentences_new = sum(1 for _ in new_corpus)\n",
    "num_tokens_new = sum(len(sentence) for sentence in new_corpus)\n",
    "\n",
    "print(f\"Le nouveau corpus contient {num_sentences_new} phrases et {num_tokens_new} mots (tokens).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement d'un nouveau modèle Word2Vec sur le corpus étendu\n",
    "new_model = train_word2vec_model(new_corpus, num_sentences_new)\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "new_model.save(\"word2vec_new_corpus.model\")\n",
    "print(\"Modèle entraîné et sauvegardé sur le corpus étendu.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e. Testez ce modèle comme en (1g) et (1h). Est-il meilleur que le précédent ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoursTAL_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
