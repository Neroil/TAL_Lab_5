{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 5 : Vector Embedding\n",
    "\n",
    "> Authors : Stefani Massimo, Häffner Edwin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: scipy in /home/neroil/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages (1.15.2)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/neroil/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /home/neroil/miniconda3/envs/CoursTAL_new/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
      "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.1\n",
      "    Uninstalling numpy-2.0.1:\n",
      "      Successfully uninstalled numpy-2.0.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.2\n",
      "    Uninstalling scipy-1.15.2:\n",
      "      Successfully uninstalled scipy-1.15.2\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installation de gensim et scipy en dernière version\n",
    "!pip install gensim scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "#Installation du modèle entraîné sur Google News \n",
    "from gensim import downloader as api\n",
    "w2v_vectors = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du modèle\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"~/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\", binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse aux questions \n",
    "\n",
    ">a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?\n",
    "\n",
    "Sur mon OS Linux, je vois que le notebook prends 4.57 GiB en mémoire. Visual studio code en prends 8.52 GiB mais je ne pense pas que c'est lié ! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La dimension de l'espace vectoriel est de 300 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Question b\n",
    "# Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?\n",
    "\n",
    "print(f\"La dimension de l'espace vectoriel est de {w2v_vectors.vector_size} dimensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du vocabulaire est de 3000000 mots et voici des mots qui sont dans le vocabulaire (ou pas): \n",
      "Connu : natural\n",
      "Connu : language\n",
      "Connu : processing\n",
      "Connu : Yverdon\n",
      "Connu : school\n",
      "Inconnu : bumfuzzle\n",
      "Inconnu : taradiddle\n",
      "Connu : collywobbles\n",
      "Inconnu : Yverdon-Les-Bains\n",
      "Inconnu : Puidoux\n"
     ]
    }
   ],
   "source": [
    "# Question c\n",
    "# Quelle est la taille du vocabulaire connu du modèle ? Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas.\n",
    "\n",
    "print(f\"La taille du vocabulaire est de {len(w2v_vectors)} mots et voici des mots qui sont dans le vocabulaire (ou pas): \")\n",
    "\n",
    "for word in [\"natural\", \"language\", \"processing\", \"Yverdon\", \"school\", \"bumfuzzle\", \"taradiddle\", \"collywobbles\", \"Yverdon-Les-Bains\", \"Puidoux\"]:\n",
    "    if word in w2v_vectors :\n",
    "        print(f\"Connu : {word}\")\n",
    "    else :\n",
    "        print(f\"Inconnu : {word}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similarité entre \"rabbit\" et \"carrot\" est de : 0.3631\n"
     ]
    }
   ],
   "source": [
    "# Question d \n",
    "# Quelle est la similarité entre les mots rabbit et carrot ? Veuillez rappeler comment on mesure les similarités entre deux mots grâce à leurs vecteurs.\n",
    "print('La similarité entre \\\"rabbit\\\" et \\\"carrot\\\" est de : %.4f' % (w2v_vectors.similarity(\"rabbit\", \"carrot\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rabbit'\t'animal'\t0.53\n",
      "'rabbit'\t'hare'\t0.61\n",
      "'rabbit'\t'bunny'\t0.64\n",
      "'rabbit'\t'easter'\t0.19\n",
      "'rabbit'\t'vertex'\t0.07\n"
     ]
    }
   ],
   "source": [
    "# Question e \n",
    "# Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la similarité entre les deux mots. Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots.\n",
    "\n",
    "pairs = [\n",
    "    ('rabbit', 'animal'), # Un lapin EST un animal\n",
    "    ('rabbit', 'hare'), # Le lièvre est un genre de lapin \"sauvage\"\n",
    "    ('rabbit', 'bunny'),  # Version cute de lapin\n",
    "    ('rabbit', 'easter'),    # lapin de Pâques\n",
    "    ('rabbit', 'vertex'), #Rien à voir\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, w2v_vectors.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question e : Discussion\n",
    "\n",
    "- On voit que lapin et animal est assez similaire ce qui fais sens\n",
    "- Lapin et lièvre sont encore plus similaire ce qui fais aussi sens\n",
    "- Un peu bizarre que rabbit et bunny ne soient pas plus similaire que ça vu que c'est littéralement le même animal, juste que bunny est la forme plus colloquial. \n",
    "- Rabbit et easter ne sont pas similaire ce qui fait sens, mais il y a quand même un lien (lapin de Pâques donc la similitude n'est pas si basse)\n",
    "- Enfin rabbit et vertex (sommet) n'ont vraiment rien à voir donc 0.07 n'est pas surprenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre awfully et good 0.3707\n"
     ]
    }
   ],
   "source": [
    "# Question f \n",
    "# Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ?\n",
    "w1 = \"awful\"\n",
    "w2 = \"good\"\n",
    "print(f'Similarité entre {w1} et {w2} %.4f' % (w2v_vectors.similarity(w1, w2)))\n",
    "\n",
    "\n",
    "# Comment expliquez-vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?\n",
    "# Je pense que awful et good peuvent être utilisé dans des même contexte, comme lorsqu'on a un article qui évalue des choses, on peut à la fois considérer quelque chose de bon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoursTAL_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
