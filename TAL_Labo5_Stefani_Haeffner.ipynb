{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 5 : Vector Embedding\n",
    "\n",
    "> Authors : Stefani Massimo, Häffner Edwin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de gensim et scipy en dernière version\n",
    "#!pip install gensim scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "#Installation du modèle entraîné sur Google News \n",
    "from gensim import downloader as api\n",
    "w2v_vectors = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du modèle\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"~/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\", binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse aux questions \n",
    "\n",
    ">a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?\n",
    "\n",
    "Sur mon OS Linux, je vois que le notebook prends 4.57 GiB en mémoire. Visual studio code en prends 8.52 GiB mais je ne pense pas que c'est lié ! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La dimension de l'espace vectoriel est de 300 dimensions\n"
     ]
    }
   ],
   "source": [
    "print(f\"La dimension de l'espace vectoriel est de {w2v_vectors.vector_size} dimensions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c. Quelle est la taille du vocabulaire connu du modèle ? Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du vocabulaire est de 3000000 mots et voici des mots qui sont dans le vocabulaire (ou pas): \n",
      "Connu : natural\n",
      "Connu : language\n",
      "Connu : processing\n",
      "Connu : Yverdon\n",
      "Connu : school\n",
      "Inconnu : bumfuzzle\n",
      "Inconnu : taradiddle\n",
      "Connu : collywobbles\n",
      "Inconnu : Yverdon-Les-Bains\n",
      "Inconnu : Puidoux\n"
     ]
    }
   ],
   "source": [
    "print(f\"La taille du vocabulaire est de {len(w2v_vectors)} mots et voici des mots qui sont dans le vocabulaire (ou pas): \")\n",
    "\n",
    "for word in [\"natural\", \"language\", \"processing\", \"Yverdon\", \"school\", \"bumfuzzle\", \"taradiddle\", \"collywobbles\", \"Yverdon-Les-Bains\", \"Puidoux\"]:\n",
    "    if word in w2v_vectors :\n",
    "        print(f\"Connu : {word}\")\n",
    "    else :\n",
    "        print(f\"Inconnu : {word}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d. Quelle est la similarité entre les mots rabbit et carrot ? Veuillez rappeler comment on mesure les similarités entre deux mots grâce à leurs vecteurs.\n",
    "\n",
    "La similarité entre deux mots est généralement mesurée en calculant la similarité cosinus entre leurs vecteurs. En gros on calcule le cosinus de l'angle entre les deux vecteurs puis si les deux vecteurs sont identiques, la similarité est de 1. Si les vecteurs sont orthogonaux, la similarité est de 0. Si les vecteurs sont opposés, la similarité est de -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similarité entre \"rabbit\" et \"carrot\" est de : 0.3631\n"
     ]
    }
   ],
   "source": [
    "print('La similarité entre \\\"rabbit\\\" et \\\"carrot\\\" est de : %.4f' % (w2v_vectors.similarity(\"rabbit\", \"carrot\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e. onsidérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la similarité entre les deux mots. Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rabbit'\t'animal'\t0.53\n",
      "'rabbit'\t'hare'\t0.61\n",
      "'rabbit'\t'bunny'\t0.64\n",
      "'rabbit'\t'easter'\t0.19\n",
      "'rabbit'\t'vertex'\t0.07\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('rabbit', 'animal'), # Un lapin EST un animal\n",
    "    ('rabbit', 'hare'), # Le lièvre est un genre de lapin \"sauvage\"\n",
    "    ('rabbit', 'bunny'),  # Version cute de lapin\n",
    "    ('rabbit', 'easter'),    # lapin de Pâques\n",
    "    ('rabbit', 'vertex'), #Rien à voir\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, w2v_vectors.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question e : Discussion\n",
    "\n",
    "- On voit que lapin et animal est assez similaire ce qui fais sens\n",
    "- Lapin et lièvre sont encore plus similaire ce qui fais aussi sens\n",
    "- Un peu bizarre que rabbit et bunny ne soient pas plus similaire que ça vu que c'est littéralement le même animal, juste que bunny est la forme plus colloquial. \n",
    "- Rabbit et easter ne sont pas similaire ce qui fait sens, mais il y a quand même un lien (lapin de Pâques donc la similitude n'est pas si basse)\n",
    "- Enfin rabbit et vertex (sommet) n'ont vraiment rien à voir donc 0.07 n'est pas surprenant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre awful et good 0.4928\n"
     ]
    }
   ],
   "source": [
    "w1 = \"awful\"\n",
    "w2 = \"good\"\n",
    "print(f'Similarité entre {w1} et {w2} %.4f' % (w2v_vectors.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comment expliquez-vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?\n",
    "\n",
    "Je pense que awful et good peuvent être utilisé dans des même contexte, comme lorsqu'on a un article qui évalue des choses, on peut à la fois considérer quelque chose de bon ou de mauvais. (Ex : The movie was awful but the acting was good). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g. En vous aidant de la documentation de Gensim sur KeyedVectors, obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353. Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés.\n",
    "\n",
    "- Le score de Pearson est une mesure de la \"force\" de la relation entre deux variables, leurs associations l'une avec l'autre. C'est une mesure qui est linéaire et qui varie entre -1 et 1. Ici, on compare les similarités entre les mots du modèle et les similarités entre les mots dans le dataset, donc les similarités jugées par des êtres humains. Le coefficient de Pearson est calculé en divisant la covariance des deux variables par le produit de leurs écarts-types. (La formule est sur le wikipédia si vous voulez : https://en.wikipedia.org/wiki/Pearson_correlation_coefficient). Ici on a un score de 0.62 ce qui indique une bonne corrélation entre les résultats du modèle et les jugements humains.\n",
    "\n",
    "- Ensuite, le score de Spearman permet de mesurer cette même force de relation mais de manière non linéaire. Il est aussi entre -1 et 1. Le coefficient de Spearman est calculé en convertissant les données en rangs, puis en appliquant la formule de Pearson sur ces rangs. Les rangs sont les positions des valeurs dans l'ordre croissant btw. Ici on a un score de 0.66 ce qui est encore mieux ce qui fait sens car utiliser les rangs permet de mieux capturer les relations non linéaires entre les variables !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de Pearson :\n",
      "  Statistique : 0.6238773472434951\n",
      "  Valeur P : 1.7963233960134136e-39\n",
      "\n",
      "Résultat de Significativité (Spearman) :\n",
      "  Statistique : 0.6589215888009288\n",
      "  Valeur P : 2.5346056459149263e-45\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "def calculate_score_pearson_spearman_wordsim353(wv):\n",
    "    \n",
    "    pearson_result, significance_result, _ = wv.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "    print(\"Résultat de Pearson :\")\n",
    "    print(f\"  Statistique : {pearson_result.statistic}\")\n",
    "    print(f\"  Valeur P : {pearson_result.pvalue}\")\n",
    "\n",
    "    print(\"\\nRésultat de Significativité (Spearman) :\")\n",
    "    print(f\"  Statistique : {significance_result.statistic}\")\n",
    "    print(f\"  Valeur P : {significance_result.pvalue}\")\n",
    "\n",
    "calculate_score_pearson_spearman_wordsim353(w2v_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">h. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données\n",
    "questions-words.txt. Attention, cette évaluation prend une dizaine de minutes, donc il vaut\n",
    "mieux commencer par tester avec un fragment de ce fichier (copier/coller les 100 premières\n",
    "analogies). Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.81, [{'section': 'capital-common-countries', 'correct': [('ATHENS', 'GREECE', 'BANGKOK', 'THAILAND'), ('ATHENS', 'GREECE', 'BEIJING', 'CHINA'), ('ATHENS', 'GREECE', 'BERLIN', 'GERMANY'), ('ATHENS', 'GREECE', 'BERN', 'SWITZERLAND'), ('ATHENS', 'GREECE', 'CAIRO', 'EGYPT'), ('ATHENS', 'GREECE', 'CANBERRA', 'AUSTRALIA'), ('ATHENS', 'GREECE', 'HAVANA', 'CUBA'), ('ATHENS', 'GREECE', 'HELSINKI', 'FINLAND'), ('ATHENS', 'GREECE', 'ISLAMABAD', 'PAKISTAN'), ('ATHENS', 'GREECE', 'MADRID', 'SPAIN'), ('ATHENS', 'GREECE', 'MOSCOW', 'RUSSIA'), ('ATHENS', 'GREECE', 'OSLO', 'NORWAY'), ('ATHENS', 'GREECE', 'OTTAWA', 'CANADA'), ('ATHENS', 'GREECE', 'PARIS', 'FRANCE'), ('ATHENS', 'GREECE', 'ROME', 'ITALY'), ('ATHENS', 'GREECE', 'STOCKHOLM', 'SWEDEN'), ('ATHENS', 'GREECE', 'TEHRAN', 'IRAN'), ('ATHENS', 'GREECE', 'TOKYO', 'JAPAN'), ('BAGHDAD', 'IRAQ', 'BANGKOK', 'THAILAND'), ('BAGHDAD', 'IRAQ', 'BEIJING', 'CHINA'), ('BAGHDAD', 'IRAQ', 'BERLIN', 'GERMANY'), ('BAGHDAD', 'IRAQ', 'CAIRO', 'EGYPT'), ('BAGHDAD', 'IRAQ', 'HANOI', 'VIETNAM'), ('BAGHDAD', 'IRAQ', 'HAVANA', 'CUBA'), ('BAGHDAD', 'IRAQ', 'HELSINKI', 'FINLAND'), ('BAGHDAD', 'IRAQ', 'ISLAMABAD', 'PAKISTAN'), ('BAGHDAD', 'IRAQ', 'KABUL', 'AFGHANISTAN'), ('BAGHDAD', 'IRAQ', 'MADRID', 'SPAIN'), ('BAGHDAD', 'IRAQ', 'MOSCOW', 'RUSSIA'), ('BAGHDAD', 'IRAQ', 'OSLO', 'NORWAY'), ('BAGHDAD', 'IRAQ', 'PARIS', 'FRANCE'), ('BAGHDAD', 'IRAQ', 'ROME', 'ITALY'), ('BAGHDAD', 'IRAQ', 'STOCKHOLM', 'SWEDEN'), ('BAGHDAD', 'IRAQ', 'TEHRAN', 'IRAN'), ('BAGHDAD', 'IRAQ', 'TOKYO', 'JAPAN'), ('BAGHDAD', 'IRAQ', 'ATHENS', 'GREECE'), ('BANGKOK', 'THAILAND', 'BEIJING', 'CHINA'), ('BANGKOK', 'THAILAND', 'BERLIN', 'GERMANY'), ('BANGKOK', 'THAILAND', 'BERN', 'SWITZERLAND'), ('BANGKOK', 'THAILAND', 'CAIRO', 'EGYPT'), ('BANGKOK', 'THAILAND', 'CANBERRA', 'AUSTRALIA'), ('BANGKOK', 'THAILAND', 'HAVANA', 'CUBA'), ('BANGKOK', 'THAILAND', 'HELSINKI', 'FINLAND'), ('BANGKOK', 'THAILAND', 'ISLAMABAD', 'PAKISTAN'), ('BANGKOK', 'THAILAND', 'KABUL', 'AFGHANISTAN'), ('BANGKOK', 'THAILAND', 'MADRID', 'SPAIN'), ('BANGKOK', 'THAILAND', 'MOSCOW', 'RUSSIA'), ('BANGKOK', 'THAILAND', 'OSLO', 'NORWAY'), ('BANGKOK', 'THAILAND', 'OTTAWA', 'CANADA'), ('BANGKOK', 'THAILAND', 'PARIS', 'FRANCE'), ('BANGKOK', 'THAILAND', 'ROME', 'ITALY'), ('BANGKOK', 'THAILAND', 'STOCKHOLM', 'SWEDEN'), ('BANGKOK', 'THAILAND', 'TEHRAN', 'IRAN'), ('BANGKOK', 'THAILAND', 'TOKYO', 'JAPAN'), ('BANGKOK', 'THAILAND', 'ATHENS', 'GREECE'), ('BEIJING', 'CHINA', 'BERLIN', 'GERMANY'), ('BEIJING', 'CHINA', 'CAIRO', 'EGYPT'), ('BEIJING', 'CHINA', 'CANBERRA', 'AUSTRALIA'), ('BEIJING', 'CHINA', 'HAVANA', 'CUBA'), ('BEIJING', 'CHINA', 'HELSINKI', 'FINLAND'), ('BEIJING', 'CHINA', 'ISLAMABAD', 'PAKISTAN'), ('BEIJING', 'CHINA', 'MADRID', 'SPAIN'), ('BEIJING', 'CHINA', 'MOSCOW', 'RUSSIA'), ('BEIJING', 'CHINA', 'OSLO', 'NORWAY'), ('BEIJING', 'CHINA', 'OTTAWA', 'CANADA'), ('BEIJING', 'CHINA', 'PARIS', 'FRANCE'), ('BEIJING', 'CHINA', 'ROME', 'ITALY'), ('BEIJING', 'CHINA', 'STOCKHOLM', 'SWEDEN'), ('BEIJING', 'CHINA', 'TEHRAN', 'IRAN'), ('BEIJING', 'CHINA', 'TOKYO', 'JAPAN'), ('BEIJING', 'CHINA', 'ATHENS', 'GREECE'), ('BEIJING', 'CHINA', 'BANGKOK', 'THAILAND'), ('BERLIN', 'GERMANY', 'BERN', 'SWITZERLAND'), ('BERLIN', 'GERMANY', 'CAIRO', 'EGYPT'), ('BERLIN', 'GERMANY', 'CANBERRA', 'AUSTRALIA'), ('BERLIN', 'GERMANY', 'HAVANA', 'CUBA'), ('BERLIN', 'GERMANY', 'HELSINKI', 'FINLAND'), ('BERLIN', 'GERMANY', 'ISLAMABAD', 'PAKISTAN'), ('BERLIN', 'GERMANY', 'MADRID', 'SPAIN'), ('BERLIN', 'GERMANY', 'MOSCOW', 'RUSSIA'), ('BERLIN', 'GERMANY', 'OSLO', 'NORWAY')], 'incorrect': [('ATHENS', 'GREECE', 'BAGHDAD', 'IRAQ'), ('ATHENS', 'GREECE', 'HANOI', 'VIETNAM'), ('ATHENS', 'GREECE', 'KABUL', 'AFGHANISTAN'), ('ATHENS', 'GREECE', 'LONDON', 'ENGLAND'), ('BAGHDAD', 'IRAQ', 'BERN', 'SWITZERLAND'), ('BAGHDAD', 'IRAQ', 'CANBERRA', 'AUSTRALIA'), ('BAGHDAD', 'IRAQ', 'LONDON', 'ENGLAND'), ('BAGHDAD', 'IRAQ', 'OTTAWA', 'CANADA'), ('BANGKOK', 'THAILAND', 'HANOI', 'VIETNAM'), ('BANGKOK', 'THAILAND', 'LONDON', 'ENGLAND'), ('BANGKOK', 'THAILAND', 'BAGHDAD', 'IRAQ'), ('BEIJING', 'CHINA', 'BERN', 'SWITZERLAND'), ('BEIJING', 'CHINA', 'HANOI', 'VIETNAM'), ('BEIJING', 'CHINA', 'KABUL', 'AFGHANISTAN'), ('BEIJING', 'CHINA', 'LONDON', 'ENGLAND'), ('BEIJING', 'CHINA', 'BAGHDAD', 'IRAQ'), ('BERLIN', 'GERMANY', 'HANOI', 'VIETNAM'), ('BERLIN', 'GERMANY', 'KABUL', 'AFGHANISTAN'), ('BERLIN', 'GERMANY', 'LONDON', 'ENGLAND')]}, {'section': 'Total accuracy', 'correct': [('ATHENS', 'GREECE', 'BANGKOK', 'THAILAND'), ('ATHENS', 'GREECE', 'BEIJING', 'CHINA'), ('ATHENS', 'GREECE', 'BERLIN', 'GERMANY'), ('ATHENS', 'GREECE', 'BERN', 'SWITZERLAND'), ('ATHENS', 'GREECE', 'CAIRO', 'EGYPT'), ('ATHENS', 'GREECE', 'CANBERRA', 'AUSTRALIA'), ('ATHENS', 'GREECE', 'HAVANA', 'CUBA'), ('ATHENS', 'GREECE', 'HELSINKI', 'FINLAND'), ('ATHENS', 'GREECE', 'ISLAMABAD', 'PAKISTAN'), ('ATHENS', 'GREECE', 'MADRID', 'SPAIN'), ('ATHENS', 'GREECE', 'MOSCOW', 'RUSSIA'), ('ATHENS', 'GREECE', 'OSLO', 'NORWAY'), ('ATHENS', 'GREECE', 'OTTAWA', 'CANADA'), ('ATHENS', 'GREECE', 'PARIS', 'FRANCE'), ('ATHENS', 'GREECE', 'ROME', 'ITALY'), ('ATHENS', 'GREECE', 'STOCKHOLM', 'SWEDEN'), ('ATHENS', 'GREECE', 'TEHRAN', 'IRAN'), ('ATHENS', 'GREECE', 'TOKYO', 'JAPAN'), ('BAGHDAD', 'IRAQ', 'BANGKOK', 'THAILAND'), ('BAGHDAD', 'IRAQ', 'BEIJING', 'CHINA'), ('BAGHDAD', 'IRAQ', 'BERLIN', 'GERMANY'), ('BAGHDAD', 'IRAQ', 'CAIRO', 'EGYPT'), ('BAGHDAD', 'IRAQ', 'HANOI', 'VIETNAM'), ('BAGHDAD', 'IRAQ', 'HAVANA', 'CUBA'), ('BAGHDAD', 'IRAQ', 'HELSINKI', 'FINLAND'), ('BAGHDAD', 'IRAQ', 'ISLAMABAD', 'PAKISTAN'), ('BAGHDAD', 'IRAQ', 'KABUL', 'AFGHANISTAN'), ('BAGHDAD', 'IRAQ', 'MADRID', 'SPAIN'), ('BAGHDAD', 'IRAQ', 'MOSCOW', 'RUSSIA'), ('BAGHDAD', 'IRAQ', 'OSLO', 'NORWAY'), ('BAGHDAD', 'IRAQ', 'PARIS', 'FRANCE'), ('BAGHDAD', 'IRAQ', 'ROME', 'ITALY'), ('BAGHDAD', 'IRAQ', 'STOCKHOLM', 'SWEDEN'), ('BAGHDAD', 'IRAQ', 'TEHRAN', 'IRAN'), ('BAGHDAD', 'IRAQ', 'TOKYO', 'JAPAN'), ('BAGHDAD', 'IRAQ', 'ATHENS', 'GREECE'), ('BANGKOK', 'THAILAND', 'BEIJING', 'CHINA'), ('BANGKOK', 'THAILAND', 'BERLIN', 'GERMANY'), ('BANGKOK', 'THAILAND', 'BERN', 'SWITZERLAND'), ('BANGKOK', 'THAILAND', 'CAIRO', 'EGYPT'), ('BANGKOK', 'THAILAND', 'CANBERRA', 'AUSTRALIA'), ('BANGKOK', 'THAILAND', 'HAVANA', 'CUBA'), ('BANGKOK', 'THAILAND', 'HELSINKI', 'FINLAND'), ('BANGKOK', 'THAILAND', 'ISLAMABAD', 'PAKISTAN'), ('BANGKOK', 'THAILAND', 'KABUL', 'AFGHANISTAN'), ('BANGKOK', 'THAILAND', 'MADRID', 'SPAIN'), ('BANGKOK', 'THAILAND', 'MOSCOW', 'RUSSIA'), ('BANGKOK', 'THAILAND', 'OSLO', 'NORWAY'), ('BANGKOK', 'THAILAND', 'OTTAWA', 'CANADA'), ('BANGKOK', 'THAILAND', 'PARIS', 'FRANCE'), ('BANGKOK', 'THAILAND', 'ROME', 'ITALY'), ('BANGKOK', 'THAILAND', 'STOCKHOLM', 'SWEDEN'), ('BANGKOK', 'THAILAND', 'TEHRAN', 'IRAN'), ('BANGKOK', 'THAILAND', 'TOKYO', 'JAPAN'), ('BANGKOK', 'THAILAND', 'ATHENS', 'GREECE'), ('BEIJING', 'CHINA', 'BERLIN', 'GERMANY'), ('BEIJING', 'CHINA', 'CAIRO', 'EGYPT'), ('BEIJING', 'CHINA', 'CANBERRA', 'AUSTRALIA'), ('BEIJING', 'CHINA', 'HAVANA', 'CUBA'), ('BEIJING', 'CHINA', 'HELSINKI', 'FINLAND'), ('BEIJING', 'CHINA', 'ISLAMABAD', 'PAKISTAN'), ('BEIJING', 'CHINA', 'MADRID', 'SPAIN'), ('BEIJING', 'CHINA', 'MOSCOW', 'RUSSIA'), ('BEIJING', 'CHINA', 'OSLO', 'NORWAY'), ('BEIJING', 'CHINA', 'OTTAWA', 'CANADA'), ('BEIJING', 'CHINA', 'PARIS', 'FRANCE'), ('BEIJING', 'CHINA', 'ROME', 'ITALY'), ('BEIJING', 'CHINA', 'STOCKHOLM', 'SWEDEN'), ('BEIJING', 'CHINA', 'TEHRAN', 'IRAN'), ('BEIJING', 'CHINA', 'TOKYO', 'JAPAN'), ('BEIJING', 'CHINA', 'ATHENS', 'GREECE'), ('BEIJING', 'CHINA', 'BANGKOK', 'THAILAND'), ('BERLIN', 'GERMANY', 'BERN', 'SWITZERLAND'), ('BERLIN', 'GERMANY', 'CAIRO', 'EGYPT'), ('BERLIN', 'GERMANY', 'CANBERRA', 'AUSTRALIA'), ('BERLIN', 'GERMANY', 'HAVANA', 'CUBA'), ('BERLIN', 'GERMANY', 'HELSINKI', 'FINLAND'), ('BERLIN', 'GERMANY', 'ISLAMABAD', 'PAKISTAN'), ('BERLIN', 'GERMANY', 'MADRID', 'SPAIN'), ('BERLIN', 'GERMANY', 'MOSCOW', 'RUSSIA'), ('BERLIN', 'GERMANY', 'OSLO', 'NORWAY')], 'incorrect': [('ATHENS', 'GREECE', 'BAGHDAD', 'IRAQ'), ('ATHENS', 'GREECE', 'HANOI', 'VIETNAM'), ('ATHENS', 'GREECE', 'KABUL', 'AFGHANISTAN'), ('ATHENS', 'GREECE', 'LONDON', 'ENGLAND'), ('BAGHDAD', 'IRAQ', 'BERN', 'SWITZERLAND'), ('BAGHDAD', 'IRAQ', 'CANBERRA', 'AUSTRALIA'), ('BAGHDAD', 'IRAQ', 'LONDON', 'ENGLAND'), ('BAGHDAD', 'IRAQ', 'OTTAWA', 'CANADA'), ('BANGKOK', 'THAILAND', 'HANOI', 'VIETNAM'), ('BANGKOK', 'THAILAND', 'LONDON', 'ENGLAND'), ('BANGKOK', 'THAILAND', 'BAGHDAD', 'IRAQ'), ('BEIJING', 'CHINA', 'BERN', 'SWITZERLAND'), ('BEIJING', 'CHINA', 'HANOI', 'VIETNAM'), ('BEIJING', 'CHINA', 'KABUL', 'AFGHANISTAN'), ('BEIJING', 'CHINA', 'LONDON', 'ENGLAND'), ('BEIJING', 'CHINA', 'BAGHDAD', 'IRAQ'), ('BERLIN', 'GERMANY', 'HANOI', 'VIETNAM'), ('BERLIN', 'GERMANY', 'KABUL', 'AFGHANISTAN'), ('BERLIN', 'GERMANY', 'LONDON', 'ENGLAND')]}])\n"
     ]
    }
   ],
   "source": [
    "word_analogies = w2v_vectors.evaluate_word_analogies(\"./question-words-small.txt\") \n",
    "\n",
    "print(word_analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'analogies : 200\n",
      "Nombre d'analogies correctes : 162\n",
      "Nombre d'analogies incorrectes : 38\n",
      "Précision : 0.81\n"
     ]
    }
   ],
   "source": [
    "# Avec seulement les cents première lignes du dataset, on trouves ces résultats :\n",
    "# (word_analogies est un tuple où le premier élément est la précision et le second élément contient les détails des sections)\n",
    "\n",
    "def print_word_analogies_data(analogies_output):\n",
    "\n",
    "\taccuracy = analogies_output[0]\n",
    "\tsection_details = analogies_output[1]\n",
    "\n",
    "\ttotal_correct = 0\n",
    "\ttotal_incorrect = 0\n",
    "\n",
    "\t# On va calculer le nombre total d'analogies correctes et incorrectes\n",
    "\tfor section in section_details:\n",
    "\t\tif 'correct' in section and 'incorrect' in section:\n",
    "\t\t\ttotal_correct += len(section['correct'])\n",
    "\t\t\ttotal_incorrect += len(section['incorrect'])\n",
    "\n",
    "\ttotal_analogies = total_correct + total_incorrect\n",
    "\n",
    "\tprint(f\"Nombre d'analogies : {total_analogies}\") # On vérifie le nombre total d'analogie, devrait être 200 car il y a 2 analogies par ligne\n",
    "\tprint(f\"Nombre d'analogies correctes : {total_correct}\")\n",
    "\tprint(f\"Nombre d'analogies incorrectes : {total_incorrect}\")\n",
    "\tprint(f\"Précision : {accuracy:.2f}\")\n",
    "\n",
    "print_word_analogies_data(word_analogies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'analogies : 38660\n",
      "Nombre d'analogies correctes : 28614\n",
      "Nombre d'analogies incorrectes : 10046\n",
      "Précision : 0.74\n"
     ]
    }
   ],
   "source": [
    "# Ensuite nous allons évaluer le modèle sur le jeu total de données\n",
    "word_analogies = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print_word_analogies_data(word_analogies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur mon super pc trop bien, ça a pris 3m35 pour le calcul !\n",
    "\n",
    "Mais bref, le score est calculé de façon très simple. Dans une analogie, on a 4 mots A, B, C et D. On veut savoir si A est à B ce que C est à D. Donc on cherche ce mot D en faisant vector(A) - vector(B) + vector(C). \n",
    "Si le mot D est en effet le mot qui est indiqué dans le fichier, alors on a une analogie correcte. On fait ça pour toutes les analogies du fichier et on divise le nombre d'analogies correctes par le nombre total d'analogies.\n",
    "\n",
    "On voit aussi que sur le corpus complet on a un score moins élevé que sur le corpus réduit. Ça fait sens car le corpus complet est plus grand et donc il y a plus de chances d'avoir des mots qui ne sont pas dans le vocabulaire du modèle. Mais ça aurait aussi pu être l'inverse, ça dépend de la chance qu'on a sur le corpus réduit.\n",
    "\n",
    "Mais on voit tout de même que le corpus réduit permet d'avoir des valeurs assez proches de celles du corpus complet, donc ça fait sens de l'utiliser pour faire des tests rapides plus tard dans le labo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. En utilisant gensim.downloader (voir question 1) récupérez le corpus qui contient les 108 pre-\n",
    "miers caractères de Wikipédia (en anglais) avec la commande : corpus = api.load('text8').\n",
    "Combien de phrases et de mots (tokens) possède ce corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    }
   ],
   "source": [
    "corpus = api.load('text8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le corpus contient 1701 phrases et 17005207 mots (tokens).\n"
     ]
    }
   ],
   "source": [
    "# Calcul du nombre de phrases et de mots (tokens) dans le corpus\n",
    "num_sentences = sum(1 for _ in corpus)\n",
    "num_tokens = sum(len(sentence) for sentence in corpus)\n",
    "\n",
    "print(f\"Le corpus contient {num_sentences} phrases et {num_tokens} mots (tokens).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus (voir la documentation de\n",
    "Word2vec). Si nécessaire, procédez progressivement, en commençant par utiliser 1% du corpus,\n",
    "puis 10%, etc., pour contrôler le temps nécessaire.\n",
    "\n",
    "> • Veuillez indiquer la dimension choisie pour le embedding de ce nouveau modèle.\n",
    "> • Combien de temps prend l’entraînement sur le corpus total ?\n",
    "> • Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "def train_word2vec_model(corpus, num_sentences, vector_size=100, window=5, min_count=5, workers=4, percent=1):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle Word2Vec sur le corpus donné.\n",
    "    \n",
    "    :param corpus: Corpus d'entraînement\n",
    "    :param num_sentences: Nombre total de phrases dans le corpus\n",
    "    :param vector_size: Dimension des vecteurs de mots\n",
    "    :param window: Taille de la fenêtre contextuelle\n",
    "    :param min_count: Fréquence minimale des mots pour être inclus dans le vocabulaire\n",
    "    :param workers: Nombre de threads à utiliser pour l'entraînement\n",
    "    :param percent: Pourcentage de phrases à utiliser pour l'entraînement. Default = 1 (100%)\n",
    "    :return: Modèle Word2Vec entraîné\n",
    "    \"\"\"\n",
    "    # Limiter le corpus à un certain pourcentage\n",
    "    num_sentences_limited = int(num_sentences * percent)\n",
    "    limited_corpus = [sentence for i, sentence in enumerate(corpus) if i < num_sentences_limited]    \n",
    "    # Entraîner le modèle Word2Vec\n",
    "    model = Word2Vec(sentences=limited_corpus, vector_size=vector_size, window=window, min_count=min_count, workers=workers)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle entraîné sur 1% du corpus.\n"
     ]
    }
   ],
   "source": [
    "model_1_percent = train_word2vec_model(corpus, num_sentences, percent=0.01)\n",
    "print(\"Modèle entraîné sur 1% du corpus.\")\n",
    "## Pour 1% il a mis 0.9 secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_percent.save(\"word2vec_model_1_percent.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle entraîné sur 10% du corpus.\n"
     ]
    }
   ],
   "source": [
    "model_10_percent = train_word2vec_model(corpus, num_sentences, percent=0.1)\n",
    "print(\"Modèle entraîné sur 10% du corpus.\")\n",
    "# Pour 10% il a mis 2.2 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10_percent.save(\"word2vec_model_10_percent.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle entraîné sur 50% du corpus.\n"
     ]
    }
   ],
   "source": [
    "model_50_percent = train_word2vec_model(corpus, num_sentences, percent=0.5)\n",
    "print(\"Modèle entraîné sur 50% du corpus.\")\n",
    "# Pour 50% il a mis 9.4 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50_percent.save(\"word2vec_model_50_percent.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle entraîné sur 100% du corpus.\n"
     ]
    }
   ],
   "source": [
    "model_100_percent = train_word2vec_model(corpus, num_sentences)\n",
    "print(\"Modèle entraîné sur 100% du corpus.\")\n",
    "# Pour 100% il a mis 20.1 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_100_percent.save(\"word2vec_model_100_percent.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du modèle 1% : 3.18 Mo\n",
      "Taille du modèle 10% : 15.41 Mo\n",
      "Taille du modèle 50% : 38.64 Mo\n",
      "Taille du modèle 100% : 56.47 Mo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71290"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Taille du modèle\n",
    "import os\n",
    "model_1_percent_size = os.path.getsize(\"word2vec_model_1_percent.model\")\n",
    "model_10_percent_size = os.path.getsize(\"word2vec_model_10_percent.model\")\n",
    "model_50_percent_size = os.path.getsize(\"word2vec_model_50_percent.model\")\n",
    "model_100_percent_size = os.path.getsize(\"word2vec_model_100_percent.model\")\n",
    "print(f\"Taille du modèle 1% : {model_1_percent_size / (1024 * 1024):.2f} Mo\")\n",
    "print(f\"Taille du modèle 10% : {model_10_percent_size / (1024 * 1024):.2f} Mo\")\n",
    "print(f\"Taille du modèle 50% : {model_50_percent_size / (1024 * 1024):.2f} Mo\")\n",
    "print(f\"Taille du modèle 100% : {model_100_percent_size / (1024 * 1024):.2f} Mo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c. Mesurez la qualité de ce modèle comme en (1g) et (1h). Ce modèle est-il meilleur que celui\n",
    "entraîné sur Google News ? Quelle est selon vous la raison de la différence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de Pearson :\n",
      "  Statistique : 0.6182272608413365\n",
      "  Valeur P : 2.184957571285799e-38\n",
      "\n",
      "Résultat de Significativité (Spearman) :\n",
      "  Statistique : 0.6290602100641124\n",
      "  Valeur P : 4.530351744300017e-40\n",
      "\n",
      "Ensuite voici les résultat sur les analogies :\n",
      "Nombre d'analogies : 200\n",
      "Nombre d'analogies correctes : 64\n",
      "Nombre d'analogies incorrectes : 136\n",
      "Précision : 0.32\n"
     ]
    }
   ],
   "source": [
    "model_100_percent.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "# Affichage des résultats de Pearson et Spearman\n",
    "calculate_score_pearson_spearman_wordsim353(model_100_percent.wv)\n",
    "# Affichage de la similarité entre \"rabbit\" et \"carrot\" pour le modèle entraîné sur 100% du corpus\n",
    "\n",
    "print(\"\\nEnsuite voici les résultat sur les analogies :\")\n",
    "# Evaluate word analogies\n",
    "word_analogies_small = model_100_percent.wv.evaluate_word_analogies(\"./question-words-small.txt\")\n",
    "\n",
    "print_word_analogies_data(word_analogies_small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ici que le modèle est légèrement moins bon que le modèle de google news ! Mais cela reste tout de même très bon pour un modèle entraîné chez nous pour Pearson et Spearman.\n",
    "\n",
    "Par contre, pour les analogies le modèle de google news est bien bien meilleurs (0.74 de précision contre 0.32). Je pense que c'est parceque le modèle de google news est simplement beaucoup plus grand et donc il a plus de chances d'avoir vu les mots dans le corpus. Le modèle de google news a été aussi entraîné sur un corpus plus diversifié (actualités) avec une dimension vectorielle plus grande (300 vs 100), ce qui lui permet de surement capturer des nuances sémantiques plus fines et des relations analogiques plus complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d. Téléchargez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus\n",
    "text8 et des dépêches économiques de Reuters fourni par l’enseignant et appelé\n",
    "wikipedia_augmented.zip (à décompresser en un fichier ‘.dat’ de 413 Mo). Entraînez un\n",
    "nouveau modèle word2vec sur ce corpus, en précisant la dimension choisie pour les embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nouveau corpus contient 7011 phrases et 70102071 mots (tokens).\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "new_corpus_path = \"./wikipedia_augmented.dat\"\n",
    "\n",
    "corpus_text8 = Text8Corpus(new_corpus_path)\n",
    "    \n",
    "sentences_list = list(corpus_text8)\n",
    "num_sentences_new = len(sentences_list)\n",
    "num_tokens_new = sum(len(sentence) for sentence in sentences_list)\n",
    "    \n",
    "\n",
    "print(f\"Le nouveau corpus contient {num_sentences_new} phrases et {num_tokens_new} mots (tokens).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'entraînement: 92.32 secondes (1.54 minutes)\n",
      "Modèle entraîné et sauvegardé sur le corpus étendu.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "# Entraînement d'un nouveau modèle Word2Vec sur le corpus étendu\n",
    "new_model = train_word2vec_model(corpus_text8, num_sentences_new, percent=1)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Temps d'entraînement: {training_time:.2f} secondes ({training_time/60:.2f} minutes)\")\n",
    "# Sauvegarde du modèle\n",
    "new_model.save(\"word2vec_new_corpus.model\")\n",
    "print(\"Modèle entraîné et sauvegardé sur le corpus étendu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du modèle: 3.71 Mo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "124372"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul de la taille du modèle\n",
    "import os\n",
    "model_size_mb = os.path.getsize(\"word2vec_new_corpus.model\") / (1024 * 1024)\n",
    "print(f\"Taille du modèle: {model_size_mb:.2f} Mo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e. Testez ce modèle comme en (1g) et (1h). Est-il meilleur que le précédent ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de Pearson :\n",
      "  Statistique : 0.4789922671821398\n",
      "  Valeur P : 1.2016493237138324e-21\n",
      "\n",
      "Résultat de Significativité (Spearman) :\n",
      "  Statistique : 0.487809233175005\n",
      "  Valeur P : 1.6756599211095256e-22\n",
      "\n",
      "Ensuite voici les résultat sur les analogies :\n",
      "Nombre d'analogies : 200\n",
      "Nombre d'analogies correctes : 92\n",
      "Nombre d'analogies incorrectes : 108\n",
      "Précision : 0.46\n"
     ]
    }
   ],
   "source": [
    "# Verification de peasrson et spearman\n",
    "calculate_score_pearson_spearman_wordsim353(new_model.wv)\n",
    "\n",
    "print(\"\\nEnsuite voici les résultat sur les analogies :\")\n",
    "word_analogies_new = new_model.wv.evaluate_word_analogies(\"./question-words-small.txt\")\n",
    "print_word_analogies_data(word_analogies_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alors là c'est un peu l'histoire opposé du modèle précédent. Le modèle n'obtient pas de bon résultat sur les corrélations de Pearson et Spearman (0.48 et 0.49 respectivement), mais il est un peu meilleur que le modèle précédent sur les analogies (0.46 contre 0.32).\n",
    "\n",
    "Je pense les résultats mauvais de Pearson et Spearman viennent du fait que le modèle est super petit (3.71 Mo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
